<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Mobile Robot</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <script>
  // Delay loading the stylesheets
  setTimeout(() => {
    const fontLink = document.createElement('link');
    fontLink.href = 'https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i&display=swap';
    fontLink.rel = 'stylesheet';
    document.head.appendChild(fontLink);

    const bootstrapIconsLink = document.createElement('link');
    bootstrapIconsLink.href = 'assets/vendor/bootstrap-icons/bootstrap-icons1.css';
    bootstrapIconsLink.rel = 'stylesheet';
    document.head.appendChild(bootstrapIconsLink);

    const boxiconsLink = document.createElement('link');
    boxiconsLink.href = 'assets/vendor/boxicons/css/boxicons.css';
    boxiconsLink.rel = 'stylesheet';
    document.head.appendChild(boxiconsLink);
  }, 3000); // 3000ms = 3 seconds
</script>


  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  
</head>

<body>

  <main id="main">

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-8">
            <div class="portfolio-details-slider swiper">
              <div class="swiper-wrapper align-items-center">
                <div class="swiper-slide">
                  <video controls="controls" class="img-fluid" muted>
                    <source src="assets/img/portfolio/2.12/apriltags.mp4">
                  </video>
                </div>

                <div class="swiper-slide">
                  <video controls="controls" class="img-fluid" muted>
                    <source src="assets/img/portfolio/2.12/cones.mp4">
                  </video>
                </div>

              </div>
              <div class="swiper-pagination"></div>
            </div>
          </div>

          <div class="col-lg-4">
            <div class="portfolio-info">
              <h3>Computer vision for april tag detection and obstacle avoidance</h3>
              <ul>
                <li><strong>Category</strong>Class project</li>
                <li><strong>Project date</strong>Spring 2023</li>
                <li><strong>Skills required</strong>Python, OpenCV, HSV filtering, AR overlays</li>
                <li><a href="https://github.com/auds2020/mobile-robot" class="btn-visit align-self-start">Github repository</a></li>
              </ul>
            </div>
          </div>
          <div class="portfolio-description">
            <div class="row gy-4">
              <div class="col-lg-6">
                <h2>About this project</h2>
                <p>
                  For 2.12, Introduction to Robotics, I was responsible for computer vision for the 
                  navigation of a mobile robot. The mobile robot is tasked with navigating to pick up a red
                   AED and bring it to a patient experiencing cardiac arrest while avoiding cones in its way. 
                   The robot chassis looked as follows and is controlled by a Jetson Nano. 
                  The arm attached the front tilts back to retrieve the AED off the stand.
                </p>
                <p>For <b>April tag detection</b>, I first need to find the internal matrix for the specific camera I’m 
                  using, so I run a calibration script and show the camera a standard checkerboard pattern. The
                  script takes snapshots of the checkerboard for 30 seconds and then calculates an internal matrix 
                  detailing the camera’s properties, thus accounting for differences in focal length, field of view,
                    etc. Showing the camera more angles of the checkerboard is actually advantageous, since it’ll 
                    provide a more complete dataset to draw from. 
                </p>
              </div>
              <div class="col-lg-6">
                <img loading="lazy" src="assets/img/portfolio/2.12/IMG_6908.jpg" class="portfolio-img" alt="">
              </div>
            </div>
            <br>
            <div class="row gy-4">
              <div class="col-lg-12">
                <p>
                  I can then input the camera matrix into my April
                    tag detection file, which constantly searches for April tags from a given family. If it detects
                      one, I detect the corners and draw a box with it. I also added some augmented reality components 
                      to the program by having each axis projected onto the center of the tag. On the top of the tag, I 
                      display the pitch, roll, and yaw of the tag relative to the camera.
                </p>
                <p>
                  The program for <b>cone detection</b> is also pretty straightforward: it applies a series of filters and
                  masks to the image, then looks for pixels which fit within the range of HSV values I’ve predetermined
                    for cones. It then looks for the largest contiguous section of pixels which satisfy these requirements, 
                    which is typically the bottom section of the cone, and then determines its center and minimum radius to
                    enclose it. Finally, it draws a circle around the object in the original image. I used HSV instead of RGB 
                    since it’s more robust under different lighting conditions, but nonetheless I would recommend tuning the 
                    program anytime the robot is operating in a new environment.
                </p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

    
    </section><!-- End Portfolio Details Section -->

  </main><!-- End #main -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>